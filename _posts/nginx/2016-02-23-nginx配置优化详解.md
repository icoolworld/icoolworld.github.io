---
layout: post
title: nginx配置优化详解
categories: nginx
---

## Nginx配置优化详解

## 一.主配置main
```
#nginx运行用户
user  nobody nobody;

#nginx进程数，建议按照cpu数目来指定，一般为它的倍数。
#查看CPU个数 grep processor /proc/cpuinfo | wc -l
worker_processes  8;

#工作进程的最大打开文件数（RLIMIT_NOFILE）的限制。 
worker_rlimit_nofile 65535;
```

## 二.event{}模块
```
events {
    使用epoll
    use epoll;
    #一个worker进程同时打开的最大连接数量,该值不能超过worker_rlimit_nofile. (ulimit -n)
    worker_connections  65535;

    #惊群问题，如果启用了accept_mutex，则工作进程将轮流接受新的连接。 否则，将通知所有工作进程去争抢新连接。
    #在高并发时，推荐设置为off，这样可以充分发挥多进程优势
    #当系统支持EPOLLEXCLUSIVE或者使用reuseport时没必要开启accept_mutex选项
    #在1.11.3之后默认是off
    accept_mutex off; 
}
```

## 三.http{}上下文

## HTTP and TCP Optimizations
## 1.Keepalive Connections
```
keepalive_requests 100 客户端可以通过单个keepalive连接进行的请求数。 默认值为100，但是使用负载生成工具进行测试尤其有用，这通常会从单个客户端发送大量请求。

keepalive_timeout 60 - 空闲的keepalive连接保持打开多长时间。

keepalive connections; 使用在upstream中

激活与上游服务器(upstream server)的连接缓存。
connections参数，设置每个worker进程保存在缓存Cache中的上游服务器(upstream servers)的最大keepalive连接的数量。超过此数量时，最近最少使用的连接将关闭。

应该特别注意的是，keepalive指令不限制与nginx工作进程可以打开的上游服务器的总数。 连接参数应设置为足够小的数量，以使上游服务器也处理新的传入连接。

upstream memcached_backend {
    server 127.0.0.1:11211;
    server 10.0.0.2:11211;

    keepalive 32;
}

server {
    ...

    location /memcached/ {
        set $memcached_key $uri;
        memcached_pass memcached_backend;
    }

}

http代理服务器设置

upstream http_backend {
    server 127.0.0.1:8080;

    keepalive 16;
}

server {
    ...

    location /http/ {
        proxy_pass http://http_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        ...
    }
}
```

## 2.sendfile配置
操作系统的sendfile（）系统调用将数据从一个文件描述符复制到另一个，经常实现零拷贝，这可以加速TCP数据传输。

    #===sendfile setting=============
    #默认off
    sendfile on;

    #Default:  tcp_nopush off;要开启该选项，必须开启sendfile on
    tcp_nopush     on;
    
    #Default:  tcp_nodelay on;
    tcp_nodelay    on;

##　3.Buffers缓冲区设置
我们可以做的另一个非常重要的调整是缓冲区大小。 如果缓冲区大小太低，Nginx将不得不写入临时文件，导致磁盘不断读写。 在作出任何决定之前，我们需要了解一些指导。

    #===缓冲区Buffer设置===
    #Default: client_body_buffer_size 8k|16k;
    client_body_buffer_size    256k;
    #Default: client_body_temp_path client_body_temp;
    #临时目录放入内存中
    client_body_temp_path    /dev/shm/client_body_temp 1 2;
    #header头缓冲区大小,默认1K
    client_header_buffer_size    8k;
    large_client_header_buffers    4 8k;
    #限制body的最大字节数，10m
    client_max_body_size       10m;

    #request_pool_size        4k;
    #connection_pool_size        512;



## 4.访问日志
记录每个请求消耗CPU和I / O周期，减少影响的一种方法是启用访问日志缓冲。 通过缓冲，NGINX不是为每个日志条目执行单独的写入操作，而是缓冲一系列条目，并在一个操作中将它们一起写入文件。
```
Syntax: access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];
access_log off;
Default:    
access_log logs/access.log combined;
Context:    http, server, location, if in location, limit_except

access_log /path/to/log.gz combined buffer=10m flush=5m;
```

## limits
ngx_http_limit_conn_module模块用于限制每个定义的密钥的连接数，特别是单个IP地址的连接数。
并非所有连接都被计数。 连接只有在具有服务器处理的请求并且整个请求头已经被读取时才被计数。
您可以设置各种限制，以帮助防止客户端消耗太多的资源，这可能会对系统的性能以及用户体验和安全性产生不利影响。 以下是一些相关指令：
http://nginx.org/en/docs/http/ngx_http_limit_conn_module.html

```
Syntax: limit_conn zone number;
Default:    —
Context:    http, server, location
```

可以配置多个limit_conn指令。 例如，以下配置将限制每个客户端IP与服务器的连接数，同时限制与虚拟服务器的总连接数：
```
limit_conn_zone $binary_remote_addr zone=perip:10m;
limit_conn_zone $server_name zone=perserver:10m;

server {
    limit_conn perip 10;
    limit_conn perserver 100;
}
```

当服务器限制连接数时，设置所需的日志记录级别。默认记录error
```
Syntax: limit_conn_log_level info | notice | warn | error;
Default:    
limit_conn_log_level error;
Context:    http, server, location
This directive appeared in version 0.8.18.
```

当超过限制的连接数时，设置响应被拒绝的请求返回的状态代码。默认503
```
Syntax: limit_conn_status code;
Default:    
limit_conn_status 503;
Context:    http, server, location
This directive appeared in version 1.3.15.
```

设置共享内存区域的参数，以保持各种密钥的状态。 特别地，状态包括当前连接数。 key可以包含文本，变量和它们的组合。 如果某个请求中KEY是空的，将不会被计算进去。
```
Syntax: limit_conn_zone key zone=name:size;
Default:    —
Context:    http

limit_conn_zone $binary_remote_addr zone=addr:10m;
```

这里，客户端IP地址作为密钥。 请注意，代替$ remote_addr，这里使用$ binary_remote_addr变量。 $ remote_addr变量的大小可以从7到15个字节不等。 存储状态在32位平台上占用32或64字节的内存，64位平台上占用64字节。 $ binary_remote_addr变量的大小始终为IPv4地址的4个字节或IPv6地址的16个字节。 32位平台上的存储状态总是占用32位或64位，64位平台上占用64字节。 一兆字节的区域可以保留约32000个32字节的状态或约16000个64字节的状态。 如果区域存储空间不足，服务器将返回503（服务临时不可用）错误到所有进一步的请求。

速度限制 limit_rate
```
Syntax: limit_rate rate;
Default:    
limit_rate 0;
Context:    http, server, location, if in location

```
限制客户端的响应传输速率。 速率以字节/秒指定。 0值禁用速率限制。 限制根据请求设置，因此如果客户端同时打开两个连接，则整体速率将是指定限制的两倍。

速率限制也可以在$ limit_rate变量中设置。 在某些条件下应限制利率的情况可能会有用：
```
server {

    if ($slow) {
        set $limit_rate 4k;
    }
}
```

limit_rate_after 设置在传输多少字节后开始限速

```
Syntax: limit_rate_after size;
Default:    
limit_rate_after 0;
Context:    http, server, location, if in location

```

eg:以下限制在传输超过500K后，传输速率为50K/s
```
location /flv/ {
    flv;
    limit_rate_after 500k;
    limit_rate       50k;
}
```


ngx_http_limit_req_module模块（0.7.21）用于限制每个定义的密钥的请求处理速率，特别是来自单个IP地址的请求的处理速率。 使用“泄漏桶”方法进行限制。
http://nginx.org/en/docs/http/ngx_http_limit_req_module.html

当且仅当在当前级别没有limit_req指令时，这些伪指令将从上一级继承。

可能有几个limit_req指令。 例如，以下配置将限制来自单个IP地址的请求的处理速率，同时限制虚拟服务器的请求处理速率：

以下限制每个IP每秒只能一个请求，服务器每秒处理的请求数不超过10个
```
limit_req_zone $binary_remote_addr zone=perip:10m rate=1r/s;
limit_req_zone $server_name zone=perserver:10m rate=10r/s;

server {
    ...
    limit_req zone=perip burst=5 nodelay;
    limit_req zone=perserver burst=10;
}
```


limit_req and limit_req_zone 限制由NGINX处理的请求的速率，这与设置limit_rate具有相同的好处。 它们还可以通过将请求速率限制为人为用户时，是一个合理的值，但是对于尝试通过请求（例如DDoS攻击中的机器人）压制应用程序的程序来说，也可以提高安全性，特别是登录页面。


https://www.nginx.com/blog/tuning-nginx/
https://www.digitalocean.com/community/tutorials/how-to-optimize-nginx-configuration
http://nosmoking.blog.51cto.com/3263888/1684114

http://www.blogjava.net/yongboy/archive/2014/07/30/416373.html

https://www.linode.com/docs/web-servers/nginx/configure-nginx-for-optimized-performance

https://seravo.fi/2013/optimizing-web-server-performance-with-nginx-and-php